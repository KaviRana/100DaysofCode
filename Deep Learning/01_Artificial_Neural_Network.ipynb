{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"Churn_Modelling.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7963\n",
       "1    2037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geography\n",
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Geography'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['RowNumber','CustomerId','Surname'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data,columns=['Geography','Gender'],drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   CreditScore        10000 non-null  int64  \n",
      " 1   Age                10000 non-null  int64  \n",
      " 2   Tenure             10000 non-null  int64  \n",
      " 3   Balance            10000 non-null  float64\n",
      " 4   NumOfProducts      10000 non-null  int64  \n",
      " 5   HasCrCard          10000 non-null  int64  \n",
      " 6   IsActiveMember     10000 non-null  int64  \n",
      " 7   EstimatedSalary    10000 non-null  float64\n",
      " 8   Exited             10000 non-null  int64  \n",
      " 9   Geography_Germany  10000 non-null  bool   \n",
      " 10  Geography_Spain    10000 non-null  bool   \n",
      " 11  Gender_Male        10000 non-null  bool   \n",
      "dtypes: bool(3), float64(2), int64(7)\n",
      "memory usage: 732.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop(columns=['Exited'])\n",
    "y = data['Exited']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(11, activation='relu', input_dim=11))\n",
    "model.add(Dense(11,activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 11)                132       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 11)                132       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276 (1.08 KB)\n",
      "Trainable params: 276 (1.08 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() #model.summary() is a function in Keras that provides a summary of the neural network model's architecture. \n",
    "#It gives a concise overview of the model, including the total number of trainable parameters and the shape of each layer's output. \n",
    "# The summary is useful for understanding the structure of the model and checking if it is built as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 3s 9ms/step - loss: 0.3143 - accuracy: 0.8678 - val_loss: 0.3404 - val_accuracy: 0.8562\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8697 - val_loss: 0.3419 - val_accuracy: 0.8575\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8689 - val_loss: 0.3413 - val_accuracy: 0.8581\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8716 - val_loss: 0.3418 - val_accuracy: 0.8569\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8700 - val_loss: 0.3435 - val_accuracy: 0.8550\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8689 - val_loss: 0.3399 - val_accuracy: 0.8587\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8694 - val_loss: 0.3454 - val_accuracy: 0.8550\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8702 - val_loss: 0.3401 - val_accuracy: 0.8581\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8711 - val_loss: 0.3422 - val_accuracy: 0.8562\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8691 - val_loss: 0.3418 - val_accuracy: 0.8569\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8694 - val_loss: 0.3391 - val_accuracy: 0.8575\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8680 - val_loss: 0.3404 - val_accuracy: 0.8556\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8695 - val_loss: 0.3455 - val_accuracy: 0.8562\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8717 - val_loss: 0.3400 - val_accuracy: 0.8569\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8700 - val_loss: 0.3401 - val_accuracy: 0.8587\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8695 - val_loss: 0.3404 - val_accuracy: 0.8594\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8706 - val_loss: 0.3403 - val_accuracy: 0.8587\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8692 - val_loss: 0.3395 - val_accuracy: 0.8594\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8703 - val_loss: 0.3409 - val_accuracy: 0.8569\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8691 - val_loss: 0.3396 - val_accuracy: 0.8587\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8692 - val_loss: 0.3403 - val_accuracy: 0.8575\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8708 - val_loss: 0.3434 - val_accuracy: 0.8600\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8708 - val_loss: 0.3398 - val_accuracy: 0.8575\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8708 - val_loss: 0.3400 - val_accuracy: 0.8581\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8691 - val_loss: 0.3427 - val_accuracy: 0.8587\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8712 - val_loss: 0.3420 - val_accuracy: 0.8569\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8708 - val_loss: 0.3410 - val_accuracy: 0.8581\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8706 - val_loss: 0.3398 - val_accuracy: 0.8587\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8712 - val_loss: 0.3396 - val_accuracy: 0.8581\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8698 - val_loss: 0.3392 - val_accuracy: 0.8612\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8706 - val_loss: 0.3394 - val_accuracy: 0.8594\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8709 - val_loss: 0.3396 - val_accuracy: 0.8594\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8709 - val_loss: 0.3419 - val_accuracy: 0.8569\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3118 - accuracy: 0.8680 - val_loss: 0.3403 - val_accuracy: 0.8587\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8716 - val_loss: 0.3399 - val_accuracy: 0.8587\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8694 - val_loss: 0.3406 - val_accuracy: 0.8569\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8709 - val_loss: 0.3392 - val_accuracy: 0.8587\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8708 - val_loss: 0.3408 - val_accuracy: 0.8562\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8711 - val_loss: 0.3401 - val_accuracy: 0.8569\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8712 - val_loss: 0.3404 - val_accuracy: 0.8587\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8719 - val_loss: 0.3400 - val_accuracy: 0.8594\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8716 - val_loss: 0.3415 - val_accuracy: 0.8581\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8719 - val_loss: 0.3405 - val_accuracy: 0.8581\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8703 - val_loss: 0.3415 - val_accuracy: 0.8594\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8720 - val_loss: 0.3405 - val_accuracy: 0.8594\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8711 - val_loss: 0.3398 - val_accuracy: 0.8587\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8712 - val_loss: 0.3394 - val_accuracy: 0.8594\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8712 - val_loss: 0.3426 - val_accuracy: 0.8556\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8694 - val_loss: 0.3400 - val_accuracy: 0.8587\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8711 - val_loss: 0.3387 - val_accuracy: 0.8569\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8691 - val_loss: 0.3417 - val_accuracy: 0.8562\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8708 - val_loss: 0.3416 - val_accuracy: 0.8562\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8702 - val_loss: 0.3392 - val_accuracy: 0.8600\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8722 - val_loss: 0.3404 - val_accuracy: 0.8594\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8719 - val_loss: 0.3452 - val_accuracy: 0.8581\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8705 - val_loss: 0.3405 - val_accuracy: 0.8587\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8706 - val_loss: 0.3412 - val_accuracy: 0.8562\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8703 - val_loss: 0.3387 - val_accuracy: 0.8587\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8714 - val_loss: 0.3396 - val_accuracy: 0.8587\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8728 - val_loss: 0.3402 - val_accuracy: 0.8594\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8722 - val_loss: 0.3404 - val_accuracy: 0.8594\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8730 - val_loss: 0.3403 - val_accuracy: 0.8606\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.3102 - accuracy: 0.8717 - val_loss: 0.3409 - val_accuracy: 0.8600\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8727 - val_loss: 0.3397 - val_accuracy: 0.8612\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8694 - val_loss: 0.3395 - val_accuracy: 0.8606\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8730 - val_loss: 0.3402 - val_accuracy: 0.8575\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8720 - val_loss: 0.3397 - val_accuracy: 0.8600\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8709 - val_loss: 0.3384 - val_accuracy: 0.8587\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8705 - val_loss: 0.3396 - val_accuracy: 0.8569\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8694 - val_loss: 0.3404 - val_accuracy: 0.8600\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8727 - val_loss: 0.3395 - val_accuracy: 0.8562\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8705 - val_loss: 0.3388 - val_accuracy: 0.8544\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8720 - val_loss: 0.3416 - val_accuracy: 0.8569\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8709 - val_loss: 0.3416 - val_accuracy: 0.8587\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8706 - val_loss: 0.3387 - val_accuracy: 0.8562\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8728 - val_loss: 0.3402 - val_accuracy: 0.8587\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8719 - val_loss: 0.3393 - val_accuracy: 0.8569\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8728 - val_loss: 0.3397 - val_accuracy: 0.8581\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8712 - val_loss: 0.3407 - val_accuracy: 0.8594\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8722 - val_loss: 0.3384 - val_accuracy: 0.8581\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8727 - val_loss: 0.3396 - val_accuracy: 0.8587\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8723 - val_loss: 0.3387 - val_accuracy: 0.8556\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8722 - val_loss: 0.3396 - val_accuracy: 0.8575\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8722 - val_loss: 0.3405 - val_accuracy: 0.8587\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8725 - val_loss: 0.3405 - val_accuracy: 0.8581\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8737 - val_loss: 0.3405 - val_accuracy: 0.8600\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8711 - val_loss: 0.3388 - val_accuracy: 0.8550\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8728 - val_loss: 0.3393 - val_accuracy: 0.8575\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8706 - val_loss: 0.3435 - val_accuracy: 0.8606\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3086 - accuracy: 0.8733 - val_loss: 0.3418 - val_accuracy: 0.8587\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8708 - val_loss: 0.3392 - val_accuracy: 0.8575\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3086 - accuracy: 0.8737 - val_loss: 0.3418 - val_accuracy: 0.8612\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8722 - val_loss: 0.3401 - val_accuracy: 0.8550\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8714 - val_loss: 0.3409 - val_accuracy: 0.8581\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3093 - accuracy: 0.8717 - val_loss: 0.3394 - val_accuracy: 0.8600\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8731 - val_loss: 0.3405 - val_accuracy: 0.8594\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8733 - val_loss: 0.3401 - val_accuracy: 0.8556\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8714 - val_loss: 0.3413 - val_accuracy: 0.8537\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8698 - val_loss: 0.3409 - val_accuracy: 0.8550\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8711 - val_loss: 0.3394 - val_accuracy: 0.8594\n"
     ]
    }
   ],
   "source": [
    "fit_log = model.fit(X_train_scaled,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.31434863805770874,\n",
       "  0.3135693073272705,\n",
       "  0.31338179111480713,\n",
       "  0.31427210569381714,\n",
       "  0.3131694793701172,\n",
       "  0.3143441081047058,\n",
       "  0.3134852349758148,\n",
       "  0.31394755840301514,\n",
       "  0.3133738338947296,\n",
       "  0.31371060013771057,\n",
       "  0.3133433163166046,\n",
       "  0.31340718269348145,\n",
       "  0.3132532835006714,\n",
       "  0.31271734833717346,\n",
       "  0.31337279081344604,\n",
       "  0.3132309317588806,\n",
       "  0.3127642571926117,\n",
       "  0.31338655948638916,\n",
       "  0.31292057037353516,\n",
       "  0.3128528892993927,\n",
       "  0.31272897124290466,\n",
       "  0.3128877878189087,\n",
       "  0.3126193583011627,\n",
       "  0.312229186296463,\n",
       "  0.3121071755886078,\n",
       "  0.3121878206729889,\n",
       "  0.3118067681789398,\n",
       "  0.3122590184211731,\n",
       "  0.3121345043182373,\n",
       "  0.31210097670555115,\n",
       "  0.3113101124763489,\n",
       "  0.3121461570262909,\n",
       "  0.3116012513637543,\n",
       "  0.31180691719055176,\n",
       "  0.3119150400161743,\n",
       "  0.311545193195343,\n",
       "  0.3121165335178375,\n",
       "  0.3115365505218506,\n",
       "  0.3115154504776001,\n",
       "  0.3114669620990753,\n",
       "  0.31151464581489563,\n",
       "  0.3109346330165863,\n",
       "  0.3113488256931305,\n",
       "  0.3110632002353668,\n",
       "  0.31101536750793457,\n",
       "  0.3110247552394867,\n",
       "  0.31079381704330444,\n",
       "  0.3108507990837097,\n",
       "  0.3110930919647217,\n",
       "  0.3108697533607483,\n",
       "  0.310981810092926,\n",
       "  0.3107120990753174,\n",
       "  0.3113868236541748,\n",
       "  0.3108975887298584,\n",
       "  0.3101385533809662,\n",
       "  0.31044071912765503,\n",
       "  0.31108367443084717,\n",
       "  0.3111326992511749,\n",
       "  0.3102439343929291,\n",
       "  0.3106886148452759,\n",
       "  0.31015291810035706,\n",
       "  0.3105999827384949,\n",
       "  0.3102078437805176,\n",
       "  0.3100336790084839,\n",
       "  0.31047025322914124,\n",
       "  0.3101155459880829,\n",
       "  0.31023532152175903,\n",
       "  0.31017041206359863,\n",
       "  0.3101152181625366,\n",
       "  0.3103463053703308,\n",
       "  0.3097969889640808,\n",
       "  0.3099004030227661,\n",
       "  0.30950549244880676,\n",
       "  0.31001973152160645,\n",
       "  0.3096056878566742,\n",
       "  0.30986276268959045,\n",
       "  0.30977097153663635,\n",
       "  0.3098025619983673,\n",
       "  0.30951404571533203,\n",
       "  0.309162974357605,\n",
       "  0.31009408831596375,\n",
       "  0.31044745445251465,\n",
       "  0.30976393818855286,\n",
       "  0.3096672296524048,\n",
       "  0.3094184100627899,\n",
       "  0.30909547209739685,\n",
       "  0.30905863642692566,\n",
       "  0.30904749035835266,\n",
       "  0.30960679054260254,\n",
       "  0.3086237609386444,\n",
       "  0.30974847078323364,\n",
       "  0.30860430002212524,\n",
       "  0.30946359038352966,\n",
       "  0.30934688448905945,\n",
       "  0.3092907667160034,\n",
       "  0.30845096707344055,\n",
       "  0.30869391560554504,\n",
       "  0.3089708089828491,\n",
       "  0.30923083424568176,\n",
       "  0.30897417664527893],\n",
       " 'accuracy': [0.8678125143051147,\n",
       "  0.8696874976158142,\n",
       "  0.8689062595367432,\n",
       "  0.8715624809265137,\n",
       "  0.8700000047683716,\n",
       "  0.8689062595367432,\n",
       "  0.8693749904632568,\n",
       "  0.8701562285423279,\n",
       "  0.87109375,\n",
       "  0.8690624833106995,\n",
       "  0.8693749904632568,\n",
       "  0.867968738079071,\n",
       "  0.8695312738418579,\n",
       "  0.8717187643051147,\n",
       "  0.8700000047683716,\n",
       "  0.8695312738418579,\n",
       "  0.8706250190734863,\n",
       "  0.8692187666893005,\n",
       "  0.870312511920929,\n",
       "  0.8690624833106995,\n",
       "  0.8692187666893005,\n",
       "  0.8707812428474426,\n",
       "  0.8707812428474426,\n",
       "  0.8707812428474426,\n",
       "  0.8690624833106995,\n",
       "  0.8712499737739563,\n",
       "  0.8707812428474426,\n",
       "  0.8706250190734863,\n",
       "  0.8712499737739563,\n",
       "  0.8698437213897705,\n",
       "  0.8706250190734863,\n",
       "  0.8709375262260437,\n",
       "  0.8709375262260437,\n",
       "  0.867968738079071,\n",
       "  0.8715624809265137,\n",
       "  0.8693749904632568,\n",
       "  0.8709375262260437,\n",
       "  0.8707812428474426,\n",
       "  0.87109375,\n",
       "  0.8712499737739563,\n",
       "  0.871874988079071,\n",
       "  0.8715624809265137,\n",
       "  0.871874988079071,\n",
       "  0.870312511920929,\n",
       "  0.8720312714576721,\n",
       "  0.87109375,\n",
       "  0.8712499737739563,\n",
       "  0.8712499737739563,\n",
       "  0.8693749904632568,\n",
       "  0.87109375,\n",
       "  0.8690624833106995,\n",
       "  0.8707812428474426,\n",
       "  0.8701562285423279,\n",
       "  0.8721874952316284,\n",
       "  0.871874988079071,\n",
       "  0.8704687356948853,\n",
       "  0.8706250190734863,\n",
       "  0.870312511920929,\n",
       "  0.8714062571525574,\n",
       "  0.8728125095367432,\n",
       "  0.8721874952316284,\n",
       "  0.8729687333106995,\n",
       "  0.8717187643051147,\n",
       "  0.8726562261581421,\n",
       "  0.8693749904632568,\n",
       "  0.8729687333106995,\n",
       "  0.8720312714576721,\n",
       "  0.8709375262260437,\n",
       "  0.8704687356948853,\n",
       "  0.8693749904632568,\n",
       "  0.8726562261581421,\n",
       "  0.8704687356948853,\n",
       "  0.8720312714576721,\n",
       "  0.8709375262260437,\n",
       "  0.8706250190734863,\n",
       "  0.8728125095367432,\n",
       "  0.871874988079071,\n",
       "  0.8728125095367432,\n",
       "  0.8712499737739563,\n",
       "  0.8721874952316284,\n",
       "  0.8726562261581421,\n",
       "  0.8723437786102295,\n",
       "  0.8721874952316284,\n",
       "  0.8721874952316284,\n",
       "  0.8725000023841858,\n",
       "  0.8737499713897705,\n",
       "  0.87109375,\n",
       "  0.8728125095367432,\n",
       "  0.8706250190734863,\n",
       "  0.8732812404632568,\n",
       "  0.8707812428474426,\n",
       "  0.8737499713897705,\n",
       "  0.8721874952316284,\n",
       "  0.8714062571525574,\n",
       "  0.8717187643051147,\n",
       "  0.8731250166893005,\n",
       "  0.8732812404632568,\n",
       "  0.8714062571525574,\n",
       "  0.8698437213897705,\n",
       "  0.87109375],\n",
       " 'val_loss': [0.34043043851852417,\n",
       "  0.3418714106082916,\n",
       "  0.3413001000881195,\n",
       "  0.3417518734931946,\n",
       "  0.3434836268424988,\n",
       "  0.33992135524749756,\n",
       "  0.3453853130340576,\n",
       "  0.3400866389274597,\n",
       "  0.34215009212493896,\n",
       "  0.34179413318634033,\n",
       "  0.33911406993865967,\n",
       "  0.3403666615486145,\n",
       "  0.3455272912979126,\n",
       "  0.3399580419063568,\n",
       "  0.3401089608669281,\n",
       "  0.3404354155063629,\n",
       "  0.3402547836303711,\n",
       "  0.3394576907157898,\n",
       "  0.34088316559791565,\n",
       "  0.33955687284469604,\n",
       "  0.34027808904647827,\n",
       "  0.3434221148490906,\n",
       "  0.33977100253105164,\n",
       "  0.33995047211647034,\n",
       "  0.34265097975730896,\n",
       "  0.3420027196407318,\n",
       "  0.3410031199455261,\n",
       "  0.33984336256980896,\n",
       "  0.3395761549472809,\n",
       "  0.3391708433628082,\n",
       "  0.33938780426979065,\n",
       "  0.33964431285858154,\n",
       "  0.34189537167549133,\n",
       "  0.34033524990081787,\n",
       "  0.3399011492729187,\n",
       "  0.3406080901622772,\n",
       "  0.3392459452152252,\n",
       "  0.34079691767692566,\n",
       "  0.3401317894458771,\n",
       "  0.3404061496257782,\n",
       "  0.33995985984802246,\n",
       "  0.341472864151001,\n",
       "  0.3404611647129059,\n",
       "  0.3415185213088989,\n",
       "  0.3405211269855499,\n",
       "  0.3397864103317261,\n",
       "  0.33936092257499695,\n",
       "  0.3426150977611542,\n",
       "  0.34004706144332886,\n",
       "  0.3387167751789093,\n",
       "  0.3416506052017212,\n",
       "  0.3415752351284027,\n",
       "  0.33918941020965576,\n",
       "  0.34043529629707336,\n",
       "  0.3452247381210327,\n",
       "  0.34050121903419495,\n",
       "  0.34121960401535034,\n",
       "  0.3387102782726288,\n",
       "  0.33957988023757935,\n",
       "  0.34016695618629456,\n",
       "  0.34042274951934814,\n",
       "  0.3402719497680664,\n",
       "  0.3408913016319275,\n",
       "  0.3397442698478699,\n",
       "  0.3395107388496399,\n",
       "  0.3402256667613983,\n",
       "  0.3397347629070282,\n",
       "  0.33842819929122925,\n",
       "  0.33955276012420654,\n",
       "  0.34036150574684143,\n",
       "  0.33950674533843994,\n",
       "  0.3388326168060303,\n",
       "  0.3415716290473938,\n",
       "  0.34160560369491577,\n",
       "  0.3386964499950409,\n",
       "  0.34017252922058105,\n",
       "  0.3392895460128784,\n",
       "  0.3397403657436371,\n",
       "  0.34070727229118347,\n",
       "  0.33843010663986206,\n",
       "  0.339599609375,\n",
       "  0.33873450756073,\n",
       "  0.33955124020576477,\n",
       "  0.340494304895401,\n",
       "  0.34052982926368713,\n",
       "  0.3405154347419739,\n",
       "  0.338840514421463,\n",
       "  0.33932963013648987,\n",
       "  0.34349238872528076,\n",
       "  0.3418264091014862,\n",
       "  0.33919501304626465,\n",
       "  0.34182068705558777,\n",
       "  0.34013625979423523,\n",
       "  0.3409014046192169,\n",
       "  0.3394252061843872,\n",
       "  0.3405136466026306,\n",
       "  0.34008491039276123,\n",
       "  0.341334730386734,\n",
       "  0.34089982509613037,\n",
       "  0.3393772840499878],\n",
       " 'val_accuracy': [0.856249988079071,\n",
       "  0.8575000166893005,\n",
       "  0.8581249713897705,\n",
       "  0.8568750023841858,\n",
       "  0.8550000190734863,\n",
       "  0.8587499856948853,\n",
       "  0.8550000190734863,\n",
       "  0.8581249713897705,\n",
       "  0.856249988079071,\n",
       "  0.8568750023841858,\n",
       "  0.8575000166893005,\n",
       "  0.8556249737739563,\n",
       "  0.856249988079071,\n",
       "  0.8568750023841858,\n",
       "  0.8587499856948853,\n",
       "  0.859375,\n",
       "  0.8587499856948853,\n",
       "  0.859375,\n",
       "  0.8568750023841858,\n",
       "  0.8587499856948853,\n",
       "  0.8575000166893005,\n",
       "  0.8600000143051147,\n",
       "  0.8575000166893005,\n",
       "  0.8581249713897705,\n",
       "  0.8587499856948853,\n",
       "  0.8568750023841858,\n",
       "  0.8581249713897705,\n",
       "  0.8587499856948853,\n",
       "  0.8581249713897705,\n",
       "  0.8612499833106995,\n",
       "  0.859375,\n",
       "  0.859375,\n",
       "  0.8568750023841858,\n",
       "  0.8587499856948853,\n",
       "  0.8587499856948853,\n",
       "  0.8568750023841858,\n",
       "  0.8587499856948853,\n",
       "  0.856249988079071,\n",
       "  0.8568750023841858,\n",
       "  0.8587499856948853,\n",
       "  0.859375,\n",
       "  0.8581249713897705,\n",
       "  0.8581249713897705,\n",
       "  0.859375,\n",
       "  0.859375,\n",
       "  0.8587499856948853,\n",
       "  0.859375,\n",
       "  0.8556249737739563,\n",
       "  0.8587499856948853,\n",
       "  0.8568750023841858,\n",
       "  0.856249988079071,\n",
       "  0.856249988079071,\n",
       "  0.8600000143051147,\n",
       "  0.859375,\n",
       "  0.8581249713897705,\n",
       "  0.8587499856948853,\n",
       "  0.856249988079071,\n",
       "  0.8587499856948853,\n",
       "  0.8587499856948853,\n",
       "  0.859375,\n",
       "  0.859375,\n",
       "  0.8606250286102295,\n",
       "  0.8600000143051147,\n",
       "  0.8612499833106995,\n",
       "  0.8606250286102295,\n",
       "  0.8575000166893005,\n",
       "  0.8600000143051147,\n",
       "  0.8587499856948853,\n",
       "  0.8568750023841858,\n",
       "  0.8600000143051147,\n",
       "  0.856249988079071,\n",
       "  0.8543750047683716,\n",
       "  0.8568750023841858,\n",
       "  0.8587499856948853,\n",
       "  0.856249988079071,\n",
       "  0.8587499856948853,\n",
       "  0.8568750023841858,\n",
       "  0.8581249713897705,\n",
       "  0.859375,\n",
       "  0.8581249713897705,\n",
       "  0.8587499856948853,\n",
       "  0.8556249737739563,\n",
       "  0.8575000166893005,\n",
       "  0.8587499856948853,\n",
       "  0.8581249713897705,\n",
       "  0.8600000143051147,\n",
       "  0.8550000190734863,\n",
       "  0.8575000166893005,\n",
       "  0.8606250286102295,\n",
       "  0.8587499856948853,\n",
       "  0.8575000166893005,\n",
       "  0.8612499833106995,\n",
       "  0.8550000190734863,\n",
       "  0.8581249713897705,\n",
       "  0.8600000143051147,\n",
       "  0.859375,\n",
       "  0.8556249737739563,\n",
       "  0.8537499904632568,\n",
       "  0.8550000190734863,\n",
       "  0.859375]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_log.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-3.63254517e-01,  3.44689237e-03,  5.34461997e-03,\n",
       "          4.12151478e-02,  2.33939495e-02,  2.03436753e-03,\n",
       "         -1.92168839e-02, -4.13912581e-03,  1.21761017e-01,\n",
       "         -1.54110715e-02, -1.16560526e-01],\n",
       "        [-1.98365137e-01, -6.02870941e-01, -2.94240683e-01,\n",
       "         -8.19305718e-01,  2.70863891e-01,  2.12915376e-01,\n",
       "         -1.76398411e-01, -1.57528758e-01, -2.69891530e-01,\n",
       "          7.11361706e-01, -2.25884408e-01],\n",
       "        [ 1.75545186e-01, -1.83297962e-01, -1.84173971e-01,\n",
       "          3.03940922e-02, -3.61543626e-01, -6.73272088e-02,\n",
       "         -2.08934307e-01,  1.17416792e-01,  2.42809102e-01,\n",
       "          5.71755394e-02, -4.25762348e-02],\n",
       "        [ 1.78886652e-01, -2.42294595e-01,  5.20508587e-01,\n",
       "          7.73882717e-02, -2.37223394e-02,  4.90636021e-01,\n",
       "          6.03435576e-01, -6.46723211e-01, -1.95407066e-02,\n",
       "         -1.51762068e-01,  1.55032527e+00],\n",
       "        [ 5.27945876e-01,  4.84854251e-01,  1.02245420e-01,\n",
       "          2.25715898e-02, -9.15761441e-02,  1.06440008e+00,\n",
       "         -6.89036012e-01, -1.00615311e+00,  1.02600217e+00,\n",
       "         -2.73565531e-01, -8.01647920e-03],\n",
       "        [ 9.32531297e-01, -2.17484534e-01, -2.16061637e-01,\n",
       "          1.86907127e-02,  1.19304232e-01, -6.68321475e-02,\n",
       "         -3.18093538e-01, -2.96021074e-01,  8.25349391e-02,\n",
       "         -1.13910092e-02, -1.53209046e-01],\n",
       "        [ 2.68838316e-01, -3.46588105e-01,  4.07140970e-01,\n",
       "         -1.93059713e-01,  6.37763739e-01,  4.98522930e-02,\n",
       "         -1.76332757e-01,  1.41737774e-01,  2.24550709e-01,\n",
       "          1.13936234e+00,  1.76410377e-01],\n",
       "        [ 2.71301605e-02,  1.09103441e-01, -4.97164398e-01,\n",
       "         -4.03817520e-02,  9.15494084e-01,  2.19621167e-01,\n",
       "          2.73121685e-01, -1.55327529e-01, -8.24153274e-02,\n",
       "          1.67598873e-01,  2.22533882e-01],\n",
       "        [-7.68046916e-01,  2.89813548e-01, -6.91356778e-01,\n",
       "         -8.47050175e-02, -2.45583549e-01, -1.97897151e-01,\n",
       "          4.62895185e-01, -3.04261506e-01, -3.62368792e-01,\n",
       "          1.60574213e-01, -4.34007645e-01],\n",
       "        [-7.69599319e-01,  2.94666123e-02, -6.82660699e-01,\n",
       "         -1.31805209e-04, -3.84802341e-01,  1.04749531e-01,\n",
       "         -3.82729352e-01,  1.46207392e-01,  4.27701652e-01,\n",
       "          1.36732936e-01,  8.80018622e-02],\n",
       "        [ 6.74872939e-03, -1.90719794e-02,  4.76299435e-01,\n",
       "          7.78432121e-04,  4.40537244e-01, -3.35566439e-02,\n",
       "         -3.46648425e-01, -7.08073601e-02,  4.60849851e-01,\n",
       "         -6.12530448e-02, -1.25289783e-01]], dtype=float32),\n",
       " array([ 0.02102052,  0.52278006,  0.25736225,  1.0944825 ,  0.35049576,\n",
       "        -0.5734482 ,  0.5046518 ,  0.1008491 ,  0.3243882 , -0.2371472 ,\n",
       "        -0.4543099 ], dtype=float32)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c02fa51790>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fit_log.history['loss'])\n",
    "plt.plot(fit_log.history['val_loss'])\n",
    "plt.plot(fit_log.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_log = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(y_log>0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
